# Zookeeper

# 1 CAP理论

## 1.1 C、A、P

1、C（Consistency）：一致性

- 在一个分布式的系统中，**同一个数据**的**所有备份**，在**同一时刻**是否有相同的值。也就是，对于同一个数据的读写，是否立刻对于所有副本都能看到一致的结果。一种比较常见的强一致性实现就是，在看到一致的结果之前，写请求不返回，读请求阻塞或者超时。
- 需要满足原子一致性，也就是任何读写都是具有原子性的，也就是对于同一个数据的写之后的读取，一定能读取到写的值，也就是**最新的值**

2、A（Avaliability）：可用性

- 在集群中一些节点故障时，集群还可以**响应读写请求**。
- 对于所有成功的请求，都需要在有限的时间内返回，也就是成功请求是有效的，可终止的。

3、P（Partition-tolerance）：分区容忍性

- 分布式系统具有多个节点，如果节点间网络中断，就会造成**分区**。
- 可能**节点间传输丢失一些消息**。

> CAP并不能全部满足，一般选择两个满足

## 1.2 CA、CP、AP

### CA（不选择）

如果选择了CA而放弃了P，若发生分区现象，为了保证C，系统需要禁止写入，此时就与A发生冲突，如果是为了保证A，则会出现正常的分区可以写入数据，有故障的分区不能写入数据，则与C就冲突了。

因此分布式系统理论上不可能选择CA架构，而必须选择CP或AP架构。

### CP

1、不要求高可用性，要求强一致性的系统

- 哪怕当前业务不可用也不能出现数据不一致的情况，如果节点间传输消息丢失导致没有同步成功，回滚更新需求

2、应用：<span style="color:red">分布式锁</span>

- 一般，如果没有获取到锁，或者获取锁失败都会选择阻塞等待或者直接失败，分布式锁必须保持所有节点看到的锁状态一致，否则认为获取锁失败

3、大部分分布式数据库都是CP系统，但是他们的一致性协议方案不同，例如：2PC、3PC等

### AP

1、要求高可用性不要求强一致性的系统

- 一旦分区发生，节点间的数据可能会不一致，每个节点使用自己的本地数据继续提供服务，这种情况下数据可能会出现不一致，系统一般会实现<span style="color:red">最终一致性</span>（在分区结束后通过一些机制将数据同步）

2、应用：具有多层缓存的系统，例如DNS、客户端缓存、浏览器缓存、进程缓存等

### 服务注册中心，选择AP还是CP？

> 服务注册中心需要解决的问题：
>
> - 服务注册：实例将自身服务信息注册到注册中心，包括服务的主机IP和服务的Port，以及暴露服务自身状态和访问协议信息等
> - 服务发现：实例请求注册中心所依赖的服务信息，服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求他们的服务

**1、zookeeper选择CP**

- 对于注册请求采用过半写和2PC的同步机制，只有更新成功这个注册请求才成功，这样读取每个节点都会读取到这个更新请求，否则会<span style="color:red">回滚已经更新的节点</span>。
- 每个节点的数据是一致的，<span style="color:red">如果过半的节点不可用，那么整个集群都不能处理注册实例请求以及读取实例的请求</span>。
- 从实际情况来分析，在使用zookeeper获取服务列表时，如果zk正在选举或者zk集群中半数以上的机器不可用，那么将无法获取数据。所以说，zk不能保证服务可用性。

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/af3b174fc0094103807bab3de6e8d3f4~tplv-k3u1fbpfcp-zoom-1.image)

**2、Eureka选择AP**

- 注册请求发送到一个Eureka实例上之后，这个Eureka会转发到集群内其他Eureka节点
- 即使某些节点失败，也不会回滚已经更新的，<span style="color:red">无论集群内哪些Eureka挂了也不会影响其他Eureka继续服务工作</span>，虽然可能读取到的数据会不一致

![image](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/56ac64f4176441af8e365eac36c8d60e~tplv-k3u1fbpfcp-zoom-1.image)

**3、Zookeeper和eureka的数据一致性问题**

先要明确一点，eureka的创建初心就是为一个注册中心，但是zk更多是作为分布式协调服务的存在，只不过因为它的特性被dubbo赋予了注册中心，它的职责更多是保证数据（配置数据，状态数据）在管辖下的所有服务之间保持一致，所有这个就不难理解为何zk被设计成CP而不是AP，**zk最核心的算法ZAB，就是为了解决分布式系统下数据在多个服务之间一致同步的问题。**

更深层的原因，zookeeper是按照CP原则构建，也就是说它必须保持每一个节点的数据都保持一致，如果zookeeper下节点断开或者集群中出现网络分割（例如交换机的子网间不能互访），那么zk会将它们从自己的管理范围中剔除，外界不能访问这些节点，即使这些节点是健康的可以提供正常的服务，所以导致这些节点请求都会丢失。

而eureka则完全没有这方面的顾虑，它的节点都是相对独立，不需要考虑数据一致性的问题，这个应该是eureka的诞生就是为了注册中心而设计，相对zk来说剔除了leader节点选取和事务日志极致，这样更有利于维护和保证eureka在运行的健壮性。

![image](https://user-gold-cdn.xitu.io/2019/9/6/16d05888fc2f78b3?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

再来看看，数据不一致性在注册服务中中会给eureka带来什么问题，无非就是某一个节点被注册的服务多，某个节点注册的服务少，在某一个瞬间可能导致某些ip节点被调用数少，某些ip节点调用数少的问题。也有可能存在一些本应该被删除而没被删除的脏数据。

**4、小结：服务注册应该选择AP还是CP**

对于服务注册来说，针对同一个服务，即使注册中心的不同节点保存的服务注册信息不相同，也并不会造成灾难性的后果，对于服务消费者来说，能消费才是最重要的，就算拿到的数据不是最新的数据，消费者本身也可以进行尝试失败重试。总比为了追求数据的一致性而获取不到实例信息整个服务不可用要好。

所以，对于服务注册来说，可用性比数据一致性更加的重要，选择AP。

### 分布式锁，是选择AP还是选择CP ？

这里实现分布式锁的方式选取了三种：

- 基于数据库实现分布式锁

- 基于redis实现分布式锁

- 基于zookeeper实现分布式锁

  

**1、基于数据库实现分布式锁**

创建表lock

```sql
CREATE TABLE `lock` (
  `method_lock` varchar(255) NOT NULL,
  `update_time` bigint DEFAULT '0',
  PRIMARY KEY (`method_lock`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
```

利用`method_lock`作为唯一主键，当进行上锁的时候进行insert动作，数据库成功录入则认为上锁成功，当数据库报出`Duplicate entry` 则表示无法获取该锁

不过这种方式对于单主却无法自动切换主从的mysql来说，基本就无法现实P分区容错性，（Mysql自动主从切换在目前并没有十分完美的解决方案）。可以说这种方式强依赖于数据库的可用性，数据库写操作是一个单点，一旦数据库挂掉，就导致锁的不可用。这种方式基本不在CAP的一个讨论范围。











































