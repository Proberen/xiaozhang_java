# ConcurrentHashMap

> 1、扩容过程中，读访问能否访问到数据，如何实现？
>
> 2、扩容过程中，写访问如何处理？
>
> 3、假设指定桶位形成红黑树，目前红黑树正在自平衡，此时的读线程是被阻塞还是什么？
>
> 4、JDK8中，统计当前散列表中的元素个数如何实现？为什么不使用AtomicLong？
>
> 5、简单说一下LastRun机制？

## jdk1.7

**一个Segment数组和多个HashEntry组成**

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy84MDMxMzcxLTM3NTMzMDU4NWEzZTE4NjkucG5nP2ltYWdlTW9ncjIvYXV0by1vcmllbnQvc3RyaXAlN0NpbWFnZVZpZXcyLzIvdy8xMDAwL2Zvcm1hdC93ZWJw?x-oss-process=image/format,png" alt="img" style="zoom:50%;" />

Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁，也就是锁分离技术，而每一个Segment元素存储的是HashEntry数组+链表，这个和HashMap的数据存储结构一样。

> ConcurrentHashMap 与HashMap和Hashtable 最大的不同在于：put和 get 两次Hash到达指定的HashEntry，第一次hash到达Segment,第二次到达Segment里面的Entry,然后在遍历entry链表.

**Segment** 是 ConcurrentHashMap 的一个内部类，主要的组成如下

```java
static final class Segment<K,V> extends ReentrantLock implements Serializable {    
  private static final long serialVersionUID = 2249069246763182397L;    
  // 和 HashMap 中的 HashEntry 作用一样，真正存放数据的桶    
  transient volatile HashEntry<K,V>[] table;    
  transient int count;        
  // 记得快速失败（fail—fast）么？    
  transient int modCount;        
  // 阈值
  transient int threshold;        
  // 负载因子    
  final float loadFactor;
}
```

**HashEntry**

```java
static final class HashEntry<K,V> {
  final int hash;
  final K key;
  volatile V value;
  volatile HashEntry<K,V> next;
}
```


### 构造方法

```java
public ConcurrentHashMap() {
  this(DEFAULT_INITIAL_CAPACITY, //默认容量16
       DEFAULT_LOAD_FACTOR, //默认负载因子0.75
       DEFAULT_CONCURRENCY_LEVEL);//默认支持线程并发数16
}
```

```java
//构造一个指定初始容量的concurrentHashMap
public ConcurrentHashMap(int initialCapacity) {
  this(initialCapacity, 
       DEFAULT_LOAD_FACTOR, 
       DEFAULT_CONCURRENCY_LEVEL);
}
```

```java
//构造一个指定初始容量和指定负载因子
public ConcurrentHashMap(int initialCapacity, float loadFactor) {
  this(initialCapacity, 
       loadFactor, 
       DEFAULT_CONCURRENCY_LEVEL);
}
```



**初始化**

- Segment的大小：大于currentlevel的第一个2的次幂

```java
public ConcurrentHashMap(int initialCapacity,//初始容量：所有Hashentry数组的长度和
                         float loadFactor, //加载因子
                         int concurrencyLevel) {//并发等级
  
  //如果负载因子小于0,初始容量小于0 段数小于0 抛异常
  if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
    throw new IllegalArgumentException();
  
  //如果segment段数大于最大阈值,那么就让其等于最大值
  if (concurrencyLevel > MAX_SEGMENTS)
    concurrencyLevel = MAX_SEGMENTS;
  
  //初始化1：Segment的大小：大于currentlevel的第一个2的次幂
  int sshift = 0;
  int ssize = 1;
  while (ssize < concurrencyLevel) {
    ++sshift;
    ssize <<= 1;
  }
  this.segmentShift = 32 - sshift;
  this.segmentMask = ssize - 1;
  
  if (initialCapacity > MAXIMUM_CAPACITY)
    initialCapacity = MAXIMUM_CAPACITY;
  
  //计算Hashentry的大小
  int c = initialCapacity / ssize;
  if (c * ssize < initialCapacity)
    ++c;
  
  int cap = MIN_SEGMENT_TABLE_CAPACITY;
  
  //cap为大于c的2的次幂
  while (cap < c)
    cap <<= 1;
  
  //保留一个segment信息
  Segment<K,V> s0 =
    new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                     (HashEntry<K,V>[])new HashEntry[cap]);
  
  Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
  
  UNSAFE.putOrderedObject(ss, SBASE, s0);
  this.segments = ss;
}
```

### put方法

```java
public V put(K key, V value) {			
  Segment<K,V> s;
  //value不能为空
  if (value == null)
    throw new NullPointerException();
  
  //第一次hash
  int hash = hash(key);
  int j = (hash >>> segmentShift) & segmentMask;
  if ((s = (Segment<K,V>)UNSAFE.getObject          
       (segments, (j << SSHIFT) + SBASE)) == null)
    s = ensureSegment(j);
  //执行segement的put方法
  return s.put(key, hash, value, false);
}
```

首先是通过key定位到要保存的具体的segment位置,然后执行segment的put方法:

```java
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
	//尝试获取锁,如果获取失败说明有其他线程竞争,则调用scanAndLockForPut自旋获取锁.
    HashEntry<K,V> node = tryLock() ? null :
        scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        HashEntry<K,V>[] tab = table;
        //确定链表头的位置
        int index = (tab.length - 1) & hash;
        HashEntry<K,V> first = entryAt(tab, index);
        //循环链表
        for (HashEntry<K,V> e = first;;) {
            if (e != null) {
            	//如果链表不是空的,且找到了相同的key,则覆盖value,返回旧的value值
                K k;
                if ((k = e.key) == key ||
                    (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                e = e.next;
            }
            //如果链表为空,则创建一个HashEntry并加入到segment中,同时会判断是否需要扩容
            else {
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);
                int c = count + 1;
                //如果数量超过阈值则需要扩容
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    rehash(node);
                else
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
    	//释放锁
        unlock();
    }
    return oldValue;
}
```
在put方法中,首先要加锁,如果获取锁失败就会通过自旋的方式阻塞保证能拿到锁.通过key的hash值来确定具体的链表头.

遍历该链表,如果不为空则判断传入的key和当前遍历的key是否相等,相等则覆盖value

如果链表为空则需要新建一个HashEntry并加入到Segment中,同时会先判断是否需要扩容.

最后会释放锁



## Jdk1.8

主要对 JDK7 做了三点改造：

① 取消分段锁机制，进一步降低冲突概率。

② 引入红黑树结构，同一个哈希槽上的元素个数超过一定阈值后，单向链表改为红黑树结构。

③ 使用了更加优化的方式统计集合内的元素数量。具体优化表现在：在 put、resize 和 size 方法中设计元素总数的更新和计算都避免了锁，使用 CAS 代替。

利用**CAS + synchronized**来保证并发更新的安全 
底层：**数组+链表+红黑树**来实现

![这里写图片描述](https://img-blog.csdn.net/20180327170909484?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Byb2dyYW1tZXJfYXQ=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 成员变量

```java
//初始化发生在第一次插入操作，默认大小为16的数组，用来存储Node节点数据，扩容时大小总是2的幂次方
transient volatile Node<K,V>[] table;

//扩容时新生成的数组，其大小为原数组的两倍
private transient volatile Node<K,V>[] nextTable;

//默认为0，用来控制table的初始化和扩容操作
//-1表示正在初始化
//-n表示有n-1个线程正在进行扩容操作
private transient volatile int sizeCtl;
```

```java
// Node：保存key，value及key的hash值的数据结构。 
// 其中value和next都用volatile修饰，保证并发的可见性。
class Node<K,V> implements Map.Entry<K,V> {
  final int hash;
  final K key;
  volatile V val;
  volatile Node<K,V> next;
  //... 省略部分代码
}

// ForwardingNode：一个特殊的Node节点，hash值为-1，其中存储nextTable的引用。 
// 只有table发生扩容的时候，ForwardingNode才会发挥作用，作为一个占位符放在table中表示当前节点为null或则已经被移动。
final class ForwardingNode<K,V> extends Node<K,V> {
  final Node<K,V>[] nextTable;
  ForwardingNode(Node<K,V>[] tab) {
    super(MOVED, null, null, null);
    this.nextTable = tab;
  }
}
```

### 构造方法

1、无参构造

```java
//默认容量16
public ConcurrentHashMap() {
}
```

2、带参数构造(1)

```java
public ConcurrentHashMap(int initialCapacity) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
               MAXIMUM_CAPACITY :
               //大于1.5x+1的2的次幂
               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
    this.sizeCtl = cap;
}
```

3、带参数构造(2)

```java
public ConcurrentHashMap(Map<? extends K, ? extends V> m) {
    this.sizeCtl = DEFAULT_CAPACITY;
    putAll(m);
}
```

4、带参数构造(3)

```java
public ConcurrentHashMap(int initialCapacity, float loadFactor) {
    this(initialCapacity, loadFactor, 1);
}
```

5、带参数构造(4)

```java
public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, 
                         int concurrencyLevel) {
    if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    if (initialCapacity < concurrencyLevel)   // Use at least as many bins
        initialCapacity = concurrencyLevel;   // as estimated threads
    long size = (long)(1.0 + (long)initialCapacity / loadFactor);
    int cap = (size >= (long)MAXIMUM_CAPACITY) ?
        MAXIMUM_CAPACITY : tableSizeFor((int)size);
    this.sizeCtl = cap;
}
```

### 初始化

```java
private final Node<K,V>[] initTable() {
  Node<K,V>[] tab; 
  int sc;
  //如果为空
  while ((tab = table) == null || tab.length == 0) {
    //如果sizeCtl小于0，等于-1，表示有其他线程正在初始化
    if ((sc = sizeCtl) < 0)
      //该线程停止，让出cpu时间片
      Thread.yield();
    
    //CAS成功，修改sc的值为-1，进行初始化
    else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
      try {
        if ((tab = table) == null || tab.length == 0) {
          //如果 sizeCtl>0 初始化大小为sizeCtl，否则初始化大小为16
          int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
          @SuppressWarnings("unchecked")
          Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
          table = tab = nt;
          //sc赋值，如果n为16,则sc = 16-16/4 = 12，
          sc = n - (n >>> 2);
        }
      } finally {
        //赋值给sizeCtl，初始化结束，sizeCtl的值>0
        sizeCtl = sc;
      }
      break;
    }
  }
  return tab;
}
```



### put方法

假设table已经初始化完成，put操作采用**CAS+synchronized**实现并发插入或更新操作： 
- 当前bucket为空时，**使用CAS操作**，将Node放入对应的bucket中。 
- **出现hash冲突，则采用synchronized关键字**。倘若当前hash对应的节点是链表的头节点，遍历链表，若找到对应的node节点，则修改node节点的val，否则在链表末尾添加node节点；倘若当前节点是红黑树的根节点，在树结构上遍历元素，更新或增加节点。 
- **倘若当前map正在扩容f.hash == MOVED**， 则跟其他线程一起进行扩容

```java
public V put(K key, V value) {
    return putVal(key, value, false);
}
```

```java
final V putVal(K key, V value, boolean onlyIfAbsent) {
  //不可以为null
  if (key == null || value == null) throw new NullPointerException();
  //获取hash值，这个值一定是正数，方便判断该节点的类型
  int hash = spread(key.hashCode());
  int binCount = 0;
  //变量table
  for (Node<K,V>[] tab = table;;) {
    Node<K,V> f; 
    int n, i, fh;
    
    //如果table是空的，进行初始化
    if (tab == null || (n = tab.length) == 0)
      tab = initTable();
    
    //如果当前位置为null，进行CAS操作插入元素
    else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
      if (casTabAt(tab, i, null,
                   new Node<K,V>(hash, key, value, null)))
        break;                   
    }
    
    //判断是否需要扩容，MOVED=-1
    else if ((fh = f.hash) == MOVED)
      tab = helpTransfer(tab, f);
    
    //解决hash冲突
    else {
      V oldVal = null;
      synchronized (f) {
        if (tabAt(tab, i) == f) {
          if (fh >= 0) {
            binCount = 1;
            for (Node<K,V> e = f;; ++binCount) {
              K ek;
              if (e.hash == hash &&
                  ((ek = e.key) == key ||
                   (ek != null && key.equals(ek)))) {
                oldVal = e.val;
                if (!onlyIfAbsent)
                  e.val = value;
                break;
              }
              Node<K,V> pred = e;
              if ((e = e.next) == null) {
                pred.next = new Node<K,V>(hash, key,
                                          value, null);
                break;
              }
            }
          }
          else if (f instanceof TreeBin) {
            Node<K,V> p;
            binCount = 2;
            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                  value)) != null) {
              oldVal = p.val;
              if (!onlyIfAbsent)
                p.val = value;
            }
          }
        }
      }
      if (binCount != 0) {
        if (binCount >= TREEIFY_THRESHOLD)
          treeifyBin(tab, i);
        if (oldVal != null)
          return oldVal;
        break;
      }
    }
  }
  addCount(1L, binCount);
  return null;
}
```

<img src="https://img-blog.csdnimg.cn/20191031173139379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpb25neW9uZ3F1YW4=,size_16,color_FFFFFF,t_70" alt="img" style="zoom: 67%;" />



### 面试

**1、加载因子不可变**

**2、为什么hash值大于等于0**

forwadingload的hash是-1

代理节点treebin的hash是-2

**3、sizeCtl**

- -1：表示当前散列表正在初始化，确保在并发条件下只会被创建一次
- 大于0：表示下次触发扩容的阈值
- 是-n：表示当前散列表正在进行扩容